devtools::load_all(".")
plotParallelCoordinate(task, autoorder = TRUE)
bike <- as.character(bike)
load("D:/Simon/Desktop/Studium/6. Semester/Bachelorarbeit/Data/bike.RData")
bike1[] <- lapply(bike, as.character())
bike1[] <- lapply(bike, as.character)
bike[] <- lapply(bike, as.character)
str(bike)
load("D:/Simon/Desktop/Studium/6. Semester/Bachelorarbeit/Data/bike.RData")
bike$season <- as.character(bike$season)
str(bike)
task = TaskRegr$new(id = "bike", backend = bike, target = "temp")
plotParallelCoordinate(task)
bike$mnth <- as.character(bike$mnth)
task = TaskRegr$new(id = "bike", backend = bike, target = "temp")
plotParallelCoordinate(task)
bike$days_since_2011 <- as.character(bike$days_since_2011)
task = TaskRegr$new(id = "bike", backend = bike, target = "temp")
plotParallelCoordinate(task)
ggplot(data, aes(x = s, y = alpha, z = logloss)) +
geom_tile(stat = "summary_2d", fun = mean, bins = gridsize) +
labs(title = "Heatmap",
fill = "logloss")+
geom_rug(alpha = 0.2, sides = "bl",
position = position_jitter(width = 0.07, height = 0.07))
devtools::load_all(".")
plotHeatmap(task, c(alpha, s)
plotHeatmap(task, c(alpha, s))
plotHeatmap(task, c(alpha, s))
plotHeatmap(task, c("alpha", "s"))
plotHeatmap(task, c(alpha, s))
#retrieve the target and features variables which are stored inside the task
df <- as.data.frame(task$data())
target <- task$target_names
features <- task$feature_names
#transform the df object into a vector
target_vector <-  df[[target]]
features
target_vector
features <- task$feature_names
#transform the df object into a vector
features_vector <-  df[[features]]
#transform the df object into a vector
features_vector <-  df[[features]][1]
#transform the df object into a vector
features_vector <-  df[[features[1]]]
features_vector
plotHeatmap <- function(task, features, gridsize = 20) {
#aufpassen auf unterschiedlichen datainput (kategorial, numerisch)
library(ggplot2)
features <- task$feature_names
#transform the df object into a vector
f <-  df[[features[1]]]
f2 <- df[[features[2]]]
ggplot(data, aes(x = f, y = f2, z = logloss)) +
geom_tile(stat = "summary_2d", fun = mean, bins = gridsize) +
labs(title = "Heatmap",
fill = "logloss")+
geom_rug(alpha = 0.2, sides = "bl",
position = position_jitter(width = 0.07, height = 0.07))
}
plotHeatmap(task, c(alpha, s))
plotHeatmap(task, c("alpha", "s"))
features
#transform the df object into a vector
f <-  df[[features[1]]]
f
f2 <- df[[features[2]]]
f2
features
target <- task$target_names
devtools::load_all(".")
plotHeatmap(task, c("alpha", "s"))
devtools::load_all(".")
plotHeatmap(task, c("alpha", "s"))
target <- task$target_names
t <-  df[[target]]
t
f2
ggplot(data, aes(x = f, y = f2, z = t)) +
geom_tile(stat = "summary_2d", fun = mean, bins = gridsize) +
labs(title = "Heatmap",
fill = "logloss")+
geom_rug(alpha = 0.2, sides = "bl",
position = position_jitter(width = 0.07, height = 0.07))
gridsize = 20
ggplot(data, aes(x = f, y = f2, z = t)) +
geom_tile(stat = "summary_2d", fun = mean, bins = gridsize) +
labs(title = "Heatmap",
fill = "logloss")+
geom_rug(alpha = 0.2, sides = "bl",
position = position_jitter(width = 0.07, height = 0.07))
devtools::load_all(".")
plotHeatmap(task, c("alpha", "s"))
df <- task$data()
df
ggplot(df, aes(x = f, y = f2, z = t)) +
geom_tile(stat = "summary_2d", fun = mean, bins = gridsize) +
labs(title = "Heatmap",
fill = "logloss")+
geom_rug(alpha = 0.2, sides = "bl",
position = position_jitter(width = 0.07, height = 0.07))
plotHeatmap(task, c("mnth", "season"))
plotHeatmap(task, c("mnth", "season"))
features <- task$feature_names
target <- task$target_names
features
target
df <- task$data()
df
#transform the df object into a vector
f <-  df[[features[1]]]
f
f2 <- df[[features[2]]]
t <-  df[[target]]
ggplot(df, aes(x = f, y = f2, z = t)) +
geom_tile(stat = "summary_2d", fun = mean, bins = gridsize) +
labs(title = "Heatmap",
fill = "logloss")+
geom_rug(alpha = 0.2, sides = "bl",
position = position_jitter(width = 0.07, height = 0.07))
features
feature <- c("mnth", "season")
features2 <- task$feature_names
target <- task$target_names
df <- task$data()
#transform the df object into a vector
f <-  df[[features[1]]]
f2 <- df[[features[2]]]
t <-  df[[target]]
f
target_ordered <- target_vector[order(target_vector, decreasing = FALSE)]
index <- round(length(target_ordered)*constrainrange)
target_subset <- target_ordered[min(index):max(index)]
targetindex <- match(target,names(df))
feature <- c("mnth", "season")
features2 <- task$feature_names
target <- task$target_names
df <- task$data()
#transform the df object into a vector
f <-  df[[features["mnth"]]]
f
#transform the df object into a vector
f <-  df[["mnth"]
f2 <- df[[features[2]]]
t <-  df[[target]]
ggplot(df, aes(x = f, y = f2, z = t)) +
geom_tile(stat = "summary_2d", fun = mean, bins = gridsize) +
labs(title = "Heatmap",
fill = "logloss")+
geom_rug(alpha = 0.2, sides = "bl",
position = position_jitter(width = 0.07, height = 0.07))
}
#transform the df object into a vector
f <-  df["mnth"]
#transform the df object into a vector
f <-  df[,"mnth"]
#transform the df object into a vector
f <-  df[,feature[1]]
f
f2 <- df[,"season"]
feature[1]
#transform the df object into a vector
f <-  df[,c(feature[1])]
#transform the df object into a vector
f <- df[[feature[1]]]
#transform the df object into a vector
f <- df[[feature[1]]]
f2 <- df[[feature[2]]]
t <-  df[[target]]
ggplot(df, aes(x = f, y = f2, z = t)) +
geom_tile(stat = "summary_2d", fun = mean, bins = gridsize) +
labs(title = "Heatmap",
fill = "logloss")+
geom_rug(alpha = 0.2, sides = "bl",
position = position_jitter(width = 0.07, height = 0.07))
devtools::load_all(".")
plotHeatmap(task, c("mnth", "season"))
task <- task
feature <- c("mnth", "season")
features2 <- task$feature_names
target <- task$target_names
df <- task$data()
#transform the df object into a vector
f <- df[[feature[1]]]
f2 <- df[[feature[2]]]
t <-  df[[target]]
ggplot(df, aes(x = f, y = f2, z = t)) +
geom_tile(stat = "summary_2d", fun = mean, bins = gridsize) +
labs(title = "Heatmap",
fill = "logloss")+
geom_rug(alpha = 0.2, sides = "bl",
position = position_jitter(width = 0.07, height = 0.07))
df <- task$data()
rm(plotHeatmap())
rm(plotHeatmap)
devtools::load_all(".")
plotHeatmap(task, c("mnth", "season"))
df[target]
df
df[[target]]
#perpare data
glmnet_ela <- readRDS("D:/Simon/Desktop/Studium/6. Semester/Bachelorarbeit/data/glmnet_ela.rds")
#data = subset(glmnet_ela, dataset == "kc1")
data = glmnet_ela[glmnet_ela$dataset == "kc1",]
data = data[, 1:3]
quantile(data, probs = 0.9)
quantile(data$alpha, probs = 0.9)
data
data$alpha <- data[alpha < quantile(data$alpha, probs = 0.9)]
data$alpha <- data[data$alpha < quantile(data$alpha, probs = 0.9)]
data$alpha <- data$alpha < quantile(data$alpha, probs = 0.9)
data$alpha, probs = 0.9
quantile(data$alpha, probs = 0.9)
quantile(data$alpha, probs = 0.9)
glmnet_ela <- readRDS("D:/Simon/Desktop/Studium/6. Semester/Bachelorarbeit/data/glmnet_ela.rds")
#data = subset(glmnet_ela, dataset == "kc1")
data = glmnet_ela[glmnet_ela$dataset == "kc1",]
data = data[, 1:3]
quantile(data$alpha, probs = 0.9)
data$alpha < quantile(data$alpha, probs = 0.9)
data$alpha <- data$alpha[data$alpha < quantile(data$alpha, probs = 0.9)]
data$alpha <- data$alpha[-data$alpha < quantile(data$alpha, probs = 0.9)]
data$alpha
quantile(data$alpha, probs = 0.9)
data$alpha <- data$alpha[-(data$alpha < quantile(data$alpha, probs = 0.9))]
data$alpha < quantile(data$alpha, probs = 0.9)
data$alpha <- data$alpha[!(data$alpha < quantile(data$alpha, probs = 0.9)),]
data$alpha
quantile(data$alpha, probs = 0.9)
data1 <- data[!(data$alpha < quantile(data$alpha, probs = 0.9)),]
data1 <- data[!(data$alpha >= quantile(data$alpha, probs = 0.9)),]
data1
data <- data[!(data$alpha >= quantile(data$alpha, probs = 0.9)),]
data
#create task to save Feature and Target Variable
task = TaskRegr$new(id = "task_glmnet", backend = data, target = "logloss")
learner = lrn("regr.ranger")
plotPartialDependence(task, learner)
plotPartialDependence(task, learner, c("alpha"))
plotPartialDependence(task, learner, c("s"))
data <- data[!(data$s >= quantile(data$s, probs = 0.9)),]
data
#create task to save Feature and Target Variable
task = TaskRegr$new(id = "task_glmnet", backend = data, target = "logloss")
plotPartialDependence(task, learner, c("s"))
#library("mlr3")
library(mlr3verse)
library(mypackage)
#library("mlr3")
library(mlr3verse)
#perpare data
glmnet_ela <- readRDS("D:/Simon/Desktop/Studium/6. Semester/Bachelorarbeit/data/glmnet_ela.rds")
#data = subset(glmnet_ela, dataset == "kc1")
data = glmnet_ela[glmnet_ela$dataset == "kc1",]
data = data[, 1:3]
#create task to save Feature and Target Variable
task = TaskRegr$new(id = "task_glmnet", backend = data, target = "logloss")
#task = TaskClassif$new(id = "task_glmnet", backend = data, target = "logloss")
print(task)
summary(as.data.table(task))
task$target_names
task$feature_names
#Define the learner and train it with the complete data
mlr_learners$keys()
learner = lrn("regr.ranger")
#additional information to the selected learner
learner$param_set
#change the current hyperparameter values by assigning a named list to this field:
#learner$param_set$values = list(cp = 0.01, xval = 10, minsplit = 10)
learner$print()
#plot current values of the task and use the learner to plot the border
library(mlr3viz)
plot_learner_prediction(learner, task) #+   geom_point(data= data, aes(fill = logloss, x = alpha, y = s), color = "green", size = 1)
#train the model
learner$train(task)
learner$model
summary(learner$model)
#prediction is not necessary?
prediction = learner$predict(task) #, row_ids = test_set
print(prediction)
##########
pdp1 <- FeatureEffect$new(model, feature = "alpha", method = "pdp")
##########
library(iml)
pdp1 <- FeatureEffect$new(model, feature = "alpha", method = "pdp")
plot(pdp1) #+
# Adds original Performance
geom_point(data= data, aes(y = logloss, x = s), color = "green", size = 1) +
# Adds original predictions
geom_point(
data = data, aes(y =  model$predict(data)[[1]], x = s), color = "pink", size = 1
)
library(ggplot2)
pdp1 <- FeatureEffect$new(model, feature = "alpha", method = "pdp")
plot(pdp1) #+
pdp1 <- FeatureEffect$new(model, feature = "alpha", method = "pdp")
model <- Predictor$new(learner, data = data)
model$print()
model$data$feature.names
model$data$X
prediction$score(measure)
prediction$score()
pdp <- FeatureEffect$new(model, feature = c("s"), method = "pdp", grid.size = 20)
pdp$print()
fitted_values <- pdp$results
pdp$plot()
pdp$feature.type
fitted_values
fitted_values
pdp <- FeatureEffect$new(model, feature = c("s"), method = "pdp", grid.size = 5)
pdp$print()
fitted_values <- pdp$results
fitted_values
pdp$plot()
pdp$feature.type
model$data$X
head(model$data$X)
model$print()
model$data$feature.names
model$data
model
summary(model)
model$print()
model$model
?FeatureEffect
pdp
pdp$grid.size
pdp$data
pdp$method
pdp$center.at
pdp$n.features
pdp$results
pdp$print()
head(model$data$X)
model$data$X
sort(model$data$X)
sort(model$data$X$s)
pdp$results
library(ISLR)
library(randomForest)
library(dplyr)
# set seed for reproducibility
set.seed(42)
data(College)
rf <- randomForest(Grad.Rate ~ ., data = College)
var1_vals <- seq(from = min(College$Outstate),
to = max(College$Outstate),
by = (max(College$Outstate) -
min(College$Outstate))/19)
var2_vals <- seq(from = min(College$perc.alumni),
to = max(College$perc.alumni),
by = (max(College$perc.alumni) -
min(College$perc.alumni))/19)
# Create a 20x20 grid
two_vals <- expand.grid(var1_vals, var2_vals)
two_vals <- arrange(two_vals, Var1, Var2)
two_rep <- College[rep(1:nrow(College), nrow(two_vals)), ]
two_rep$Outstate <- rep(two_vals$Var1, each = nrow(College))
two_rep$perc.alumni <- rep(two_vals$Var2, each = nrow(College))
two_pred <- predict(rf, two_rep)
two_rep$pred <- two_pred
two_agg <- group_by(two_rep, Outstate, perc.alumni) %>%
summarise(mean_pred = mean(pred))
z <- matrix(two_agg$mean_pred, nrow = length(var1_vals), byrow = TRUE)
# Set color range (using grayscale)
jet.colors <- colorRampPalette( c("#ffffff", "#2a2a2a") )
# Generate the desired number of colors from this palette
nbcol <- 100
color <- jet.colors(nbcol)
# Compute the z-value at the facet centers
zfacet <- z[-1, -1] +
z[-1, -1 * length(var1_vals)] +
z[-1 * length(var2_vals), -1] +
z[-1 * length(var1_vals), -1 * length(var2_vals)]
# Recode facet z-values into color indices
facetcol <- cut(zfacet, nbcol)
# Use persp for 3D plotting
persp(x = var1_vals, y = var2_vals, z = z, theta = -45,
xlab = "\nOut of State Tuition",
ylab = "\nPercentage Alumni Donating",
zlab = "\nPredicted Value",
cex.lab = 1,
ticktype = "detailed",
col = color[facetcol])
z
two_agg$mean_pred
data(College)
College
min(College$Grad.Rate)
var1_vals
two_vals
tail(College$Grad.Rate)
sort(College$Grad.Rate,partial=n-1)[n-1]
sort(College$Grad.Rate,partial=1)[1]
sort(College$Grad.Rate,partial=2)[1]
sort(College$Grad.Rate,partial=2)
sort(College$Grad.Rate,partial=2)[2]
?sort
sort(College$Grad.Rate)[2]
sort(College$Grad.Rate,partial = 1)[2]
sort(College$Grad.Rate,partial = 3)[2]
sort(College$Grad.Rate,partial = 4)[2]
sort(College$Grad.Rate,partial = 2)[2]
sort(College$Grad.Rate,partial = 1)[2]
sort(College$Grad.Rate,decreasing = TRUE)[2]
sort(College$Grad.Rate,decreasing = FALSE)[2]
sort(College$Grad.Rate,decreasing = FALSE)[1]
z
min(z)
pdp <- FeatureEffect$new(model, feature = c("s"), method = "pdp", grid.size = 10)
pdp$print()
head(model$data$X)
pdp$results
model$data$X
?mypackage
?plotPartialDependence
devtools::load_all(".")
?mypackage
summary(glmnet_ela)
#### summary statistics
tapply(glmnet_ela, glmnet_ela$dataset, summary)
#### summary statistics
tapply(glmnet_ela, glmnet_ela, summary)
#### summary statistics
tapply(glmnet_ela, glmnet_ela$dataset, summary)
glmnet_ela$dataset
glmnet_ela
#### summary statistics
summary(glmnet_ela)
#### summary statistics
tapply(glmnet_ela, dataset, summary)
glmnet_ela$dataset
#### summary statistics
library("purrr")
glmnet_ela %>%                               # Summary by group using purrr
split(.$dataset) %>%
map(summary)
head(a)
a <-  glmnet_ela %>%                               # Summary by group using purrr
split(.$dataset) %>%
map(summary)
head(a)
apply(glmnet_ela, glmnet_ela$dataset, summary)
tapply(glmnet_ela, glmnet_ela$dataset, summary)
tapply(glmnet_ela$logloss, glmnet_ela$dataset, summary)
library(data.table)
setDT(glmnet_ela)
glmnet_ela[, as.list(summary(logloss)), by = dataset]
glmnet_ela[, as.list(summary()), by = dataset]
with( glmnet_ela , aggregate( glmnet_ela , by=list(dataset) , FUN=summary)  )
#############
usethis::use_data(data = glmnet_ela[glmnet_ela$dataset == "kc1",])
#############
usethis::use_data(data = glmnet_ela[glmnet_ela$dataset == "kc1",], glmnet_ela)
#############
usethis::use_data(data, glmnet_ela)
load("D:/Simon/Desktop/Studium/6. Semester/Bachelorarbeit/Code/package/data/data.rda")
load("D:/Simon/Desktop/Studium/6. Semester/Bachelorarbeit/Code/package/data/glmnet_ela.rda")
#############
usethis::use_data(data)
usethis::use_data_raw(glmnet_ela)
usethis::use_data_raw("glmnet_ela")
View(glmnet_ela)
a <-  glmnet_ela %>%                               # Summary by group using purrr
split(.$dataset) %>%
map(summary)
head(a)
#base
tapply(glmnet_ela$logloss, glmnet_ela$dataset, summary)
#dt
library(data.table)
setDT(glmnet_ela)
glmnet_ela[, as.list(summary(logloss)), by = dataset]
head(glmnet_ela)
devtools::load_all(".")
/document
document()
library(roxygen2)
document()
/document
\document
devtools::load_all(".")
print(glmnet_ela)
############# create Data
glmnet_ela <- data
usethis::use_data(glmnet_ela)
load("D:/Simon/Desktop/Studium/6. Semester/Bachelorarbeit/Code/.RData")
load("D:/Simon/Desktop/Studium/6. Semester/Bachelorarbeit/Code/.RData")
?my_package
?mypackage
?glmnet_ela
?iris
devtools::load_all(".")
?glmnet_ela
?iris
devtools::load_all(".")
?iris
devtools::load_all(".")
?glmnet_ela
?glmnet_ela
?datasets
?glmnet_ela
?iris
?glmnet_ela
glmnet_ela
glmnet_ela
devtools::load_all(".")
devtools::install_github("SimonPradel/mypackage")
library(devtools)
devtools::install_github("SimonPradel/mypackage")
git clone
